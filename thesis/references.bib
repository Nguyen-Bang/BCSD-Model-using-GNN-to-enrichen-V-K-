% References

@article{bert2019,
    title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
    journal={arXiv preprint arXiv:1810.04805},
    year={2019}
}

@inproceedings{gat2018,
    title={Graph Attention Networks},
    author={Veličković, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio, Pietro and Bengio, Yoshua},
    booktitle={International Conference on Learning Representations},
    year={2018}
}

@inproceedings{angr2016,
    title={angr-The Next Generation of Binary Analysis},
    author={Shoshitaishvili, Yan and Wang, Ruoyu and Salls, Christopher and Stephens, Nick and Polino, Mario and Dutcher, Audrey and Grosen, John and Feng, Siji and Hauser, Christophe and Kruegel, Christopher and Vigna, Giovanni},
    booktitle={IEEE Cybersecurity Development (SecDev)},
    year={2016}
}

% Add more references as needed
